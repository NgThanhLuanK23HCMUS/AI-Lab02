\documentclass[12pt, a4paper]{article}

% --- PACKAGE LOADING ---
% Font and Language
\usepackage{fontspec} % For Unicode font support (XeLaTeX/LuaLaTeX)
\usepackage{polyglossia} % For multilingual support
\setmainlanguage{vietnamese}
\setmainfont{Arial} % A standard, widely available font

% Page Layout and Headers
\usepackage[left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\usepackage{fancyhdr}

% Graphics and TikZ
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{positioning, arrows.meta, trees, calc, shapes.geometric}

% Math and Symbols
\usepackage{amsmath,amssymb}
\usepackage{cancel}

% Tables and Lists
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{enumitem}

% Verbatim and Code
\usepackage{fancyvrb} % For Verbatim environments
\usepackage{fvextra}  % To allow Verbatim inside other environments

% Utilities
\usepackage{float}
\usepackage{titlesec}
\usepackage{natbib} % For handling citations like \citep

% Hyperlinks (should generally be last)
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={Lab03: Học máy},
    pdfauthor={Nguyễn Thành Luân},
}


% --- CUSTOM CONFIGURATIONS ---
% Header and Footer Style
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\nouppercase{\leftmark}}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}

% Section Numbering and Formatting
\renewcommand{\thesection}{\Roman{section}}
\renewcommand{\thesubsection}{\arabic{subsection}}
\renewcommand{\thesubsubsection}{\arabic{subsection}.\arabic{subsubsection}}
\titleformat{\subsubsection}[runin]
  {\normalfont\normalsize\bfseries}
  {\thesubsubsection}{1em}{}
  [\vspace{0.5em}]
\titlespacing*{\subsubsection}{2em}{1ex plus .2ex minus .2ex}{0.5ex}


\begin{document}

% --- TITLE PAGE ---
\begin{titlepage}
    \centering
    \fontsize{16pt}{18pt}\selectfont
    \textbf{TRƯỜNG ĐẠI HỌC KHOA HỌC TỰ NHIÊN} \\
    \textbf{KHOA CÔNG NGHỆ THÔNG TIN} \\[1cm]

    \includegraphics[width=0.35\textwidth]{img/logohcmus.png} \\[1cm]

    {\fontsize{24pt}{26pt}\selectfont \textbf{Lab03: Học máy}} \\[1cm]

    \vspace{0.5cm}

    \begin{center}
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{@{}ll}
            \textbf{Môn:} & Cơ sở trí tuệ nhân tạo \\[13pt]
            \textbf{Giáo viên hướng dẫn:} & Bùi Tiến Lên \\
                                          & Lê Nhựt Nam \\
                                          & Võ Nhật Tân\\[13pt]
            \textbf{Lớp:} & 23CLC03 \\[13pt]
            \textbf{Họ tên:} & Nguyễn Thành Luân \\[13pt]
            \textbf{Mã số sinh viên:} & 23127296 \\[13pt]
        \end{tabular}
    \end{center}

    \vfill

    {\Large \textbf{Hồ Chí Minh, 30/07/2025}}
\end{titlepage}

\tableofcontents
\newpage

% --- ABSTRACT ---
\begin{abstract}
    Giá trị Shapley (Shapley Value, SV) thường đường dùng trong các AI minh bạch (explainable AI, XAI) nhưng việc xấp xỉ và suy diễn giá trị này vẫn còn gặp nhiều khó khăn. Điều này cho những kết quả và kết luận sai lệch. Do đó, nhóm nghiên cứu nêu lên định lý bất biến của SV, từ đó xây dựng phương pháp tính SV đối với các biến phân loại mà chịu ảnh hưởng nhiều từ bởi công thức mã hóa (encoding). Đối với cây lựa chọn (Decision Tree), nhờ việc tận dụng cấu trúc đặc trưng của cây , nhóm nghiên cứu đưa ra được hai phương pháp xấp xỉ SV với độ chính xác cao hơn các phương pháp khác lâm thời. Hai phương pháp được chạy giả lập và so sánh cùng với các phương pháp lâm thời, điều này chỉ ra lợi thế thực tiễn của phương pháp nhóm nghiên cứu đưa ra. Cuối cùng, Nhóm nghiên cứu đánh giá các hạn chế của SV với tiêu chí là là một giải thích cục bộ (local explaination). Các pháp trên được xây dựng thành một python package.
\end{abstract}

\section{Giới thiệu}

Xu hướng của việc áp dụng AI vào nghiên cứu khoa học, kinh tế, tài chính, sản xuất ngày càng phát triển mạnh hơn. Nhu cầu suy diễn và đánh giá được các ai (ai model) ngày càng cần thiết. Thực tế rằng các model ai thường không hề tường minh, những model này gọi là black-box ai và chiếm đại đa số. Nhưng người sử dụng ai models có nhu cầu thiết yếu để có thể xét tính cường độ ảnh hưởng ( tính quan trọng) của biến số đầu vào lên kết quả, cũng như xác định model có sự thiên vị (bias) đối với một hay những biến số. Việc xét trọng tố toàn cục (global importance) bằng phương pháp tiêu chuẩn~\citep{Breiman2001} còn rất yếu kém về mảng giải thích các dự đoán cục bộ (local prediction). Công cuộc tìm kiếm giải pháp khắc phục vấn đề trên vẫn luôn là vấn đề nóng hổi của AI minh bạch (Explainable AI , XAI).

Một trong những phương pháp diễn giải phổ biến nhất là Shapley Values (SV), một khái niệm bắt nguồn từ Lý thuyết Trò chơi Hợp tác (Cooperative Game Theory)~\citep{Shapley1953}. SV cung cấp một cách "công bằng" để đánh giá sự đóng góp của từng biến đầu vào vào một dự đoán cụ thể của mô hình. Mặc dù được sử dụng rộng rãi, việc ước tính và diễn giải SV có thể gặp nhiều thách thức, dẫn đến các suy luận và giải thích không chính xác. Bài báo "Accurate Shapley Values for explaining tree-based models" của Amoukou và cộng sự đã chỉ ra hai vấn đề lớn trong các phương pháp hiện tại:

\begin{itemize}
    \item{Xử lý sai các biến hạng mục (categorical variables): Các phương pháp mã hóa phổ biến (như One-Hot-Encoding) làm thay đổi số lượng biến, và việc tính toán SV bằng cách cộng dồn SV của các biến được mã hóa là không chính xác về mặt lý thuyết và dẫn đến kết quả sai lệch.}
    \item{Độ chệch (bias) của các thuật toán hiện đại: Thuật toán tiên tiến nhất cho các mô hình dựa trên cây, TreeSHAP, có độ chệch cao khi các biến đầu vào có sự phụ thuộc lẫn nhau.}
\end{itemize}

Bài viết chỉ ra rằng thuật toán tiên tiến nhất lâm thời TreeSHAP~\citep{Lundberg2020}, có độ bias cao khi các biến số ban đầu phụ thuộc lẫn nhau. Vì thế, họ đã xây dựng một phép tính xấp SV chính xác hơn dựa trên lý thuyết xác suất thống kê.
Hơn nữa, khi áp dụng TReeSHAP đối với biến phân loại , bài viết chỉ ra rằng việc TReeSHAP xấp xỉ SV bằng phương pháp lấy tổng SV của các biến phân loại sau chuyển mã là sai trái và dẫn tới nhưng phân tích nhảm nhí. Thay vào đó , những phép xấp xỉ của nhóm đã đem lại sự xấp xỉ chính xác và giảm thiểu bia. Những đóng góp đều đã được tập hợp thành một python package.

Báo cáo này được cấu trúc thành sáu chương theo yêu cầu của đề bài. Chương II trình bày các công trình liên quan trong lĩnh vực XAI và tính toán SV. Chương III cung cấp kiến thức nền tảng về Cây quyết định và Shapley Values. Chương IV đi sâu vào phương pháp luận được đề xuất trong bài báo. Chương V phân tích các thí nghiệm và kết quả đã thực hiện. Cuối cùng, Chương VI tổng kết các kết quả chính, thảo luận về các hạn chế và đề xuất hướng nghiên cứu trong tương lai.

\section{Các công trình liên quan (Related Works)}

Lĩnh vực Trí tuệ Nhân tạo Giải thích được (Explainable AI - XAI) đã và đang phát triển mạnh mẽ nhằm đáp ứng nhu cầu hiểu rõ các mô hình học máy phức tạp. Chương này sẽ điểm qua các nghiên cứu liên quan đến việc diễn giải mô hình, so sánh các phương pháp tiếp cận hiện có, chỉ ra các khoảng trống nghiên cứu và định vị vị trí của công trình được phân tích trong bối cảnh chung.

\subsection{Tổng quan các Nghiên cứu Liên quan}

Các phương pháp diễn giải mô hình thường được chia thành hai loại: toàn cục (global) và cục bộ (local). Các phương pháp toàn cục, như đo lường tầm quan trọng bằng hoán vị (permutation importance), cung cấp cái nhìn tổng thể về các biến ảnh hưởng đến mô hình~\citep{Breiman2001}. Tuy nhiên, chúng không đủ để giải thích cho từng dự đoán riêng lẻ.

Do đó, các phương pháp giải thích cục bộ đã ra đời và thu hút nhiều sự chú ý. Một số phương pháp nền tảng và phổ biến bao gồm:
\begin{itemize}
    \item \textbf{Partial Dependence Plot (PDP)}: Trực quan hóa ảnh hưởng trung bình của một hoặc hai biến lên kết quả dự đoán của mô hình~\citep{Friedman2001}. %% ADDED CITATION
    \item \textbf{Individual Conditional Expectation (ICE)}: Là một phiên bản chi tiết hơn của PDP, hiển thị đường dự đoán cho từng quan sát riêng lẻ khi một biến thay đổi, giúp phát hiện các tương tác không đồng nhất~\citep{Goldstein2015}. %% ADDED CITATION
    \item \textbf{Local Surrogate (LIME)}: Là một phương pháp độc lập với mô hình (model-agnostic), hoạt động bằng cách xây dựng một mô hình đơn giản (ví dụ: hồi quy tuyến tính) để xấp xỉ và giải thích hành vi của mô hình hộp đen phức tạp tại một vùng lân cận của dự đoán cần giải thích~\citep{Ribeiro2016}. %% ADDED CITATION
\end{itemize}

Trong bối cảnh đó, Shapley Values (SV), một khái niệm từ Lý thuyết Trò chơi Hợp tác~\citep{Shapley1953}, đã được điều chỉnh để áp dụng cho XAI nhằm đánh giá sự đóng góp "công bằng" của mỗi biến vào một dự đoán cụ thể~\citep{Lundberg2017}. Ý tưởng cốt lõi là phân tích hành vi của mô hình bằng cách loại bỏ các biến và xem xét các ``hàm dự đoán rút gọn'' (reduced predictors)~\citep{Covert2020b}.

\subsection{So sánh với các Phương pháp Tiếp cận Hiện có}

Việc tính toán SV đối mặt với thách thức lớn là ước tính kỳ vọng có điều kiện, đặc biệt khi các biến phụ thuộc lẫn nhau~\citep{Aas2020}. Các phương pháp hiện có giải quyết vấn đề này theo nhiều cách:

\begin{enumerate}
    \item \textbf{Các phương pháp tổng quát:} Một số phương pháp cố gắng mô hình hóa trực tiếp phân phối đồng thời của các biến, ví dụ như sử dụng phân phối Gaussian hoặc vine copula, để lấy mẫu từ các phân phối có điều kiện~\citep{Aas2021}. Các phương pháp khác thậm chí huấn luyện một mô hình riêng cho mỗi tập hợp con các biến, cho kết quả chính xác nhưng cực kỳ tốn kém về mặt tính toán~\citep{Covert2020b}.

    \item \textbf{TreeSHAP (Phương pháp chuyên biệt cho mô hình cây):} Đây là phương pháp tiên tiến nhất (state-of-the-art) dành riêng cho các mô hình dựa trên cây~\citep{Lundberg2020, Lundberg2017}. TreeSHAP vượt trội hơn các phương pháp lấy mẫu vì nó có thể tính toán chính xác giá trị SV bằng cách khai thác hiệu quả cấu trúc của cây~\citep{Lundberg2020}. Tuy nhiên, điểm yếu chí mạng của TreeSHAP là nó dựa trên một giả định đơn giản hóa quá mức: nó cho rằng xác suất có điều kiện có thể được phân tách theo đường đi quyết định trong cây (một dạng tính chất Markov)~\citep{Chen2020, Aas2020}. Giả định này thường bị vi phạm trong thực tế khi các biến có sự tương quan, dẫn đến việc TreeSHAP trở nên ``có độ chệch cao khi các biến phụ thuộc''\citep{Aas2020}.
\end{enumerate}

\subsection{Xác định các Khoảng trống Nghiên cứu}

Từ việc so sánh trên, có thể xác định hai khoảng trống nghiên cứu lớn mà bài báo này nhắm đến để giải quyết:
\begin{itemize}
    \item \textbf{Độ chệch của TreeSHAP với dữ liệu phụ thuộc:} Tồn tại một khoảng trống lớn về một phương pháp vừa có thể khai thác hiệu quả cấu trúc của cây như TreeSHAP, vừa phải đủ chính xác khi đối mặt với sự phụ thuộc phổ biến giữa các biến. Giả định của TreeSHAP là quá mạnh và không thực tế, tạo ra nhu cầu về các bộ ước tính kỳ vọng có điều kiện tốt hơn~\citep{Aas2020}.
    \item \textbf{Thiếu phương pháp luận đúng đắn cho biến hạng mục:} Chưa có một phương pháp chuẩn và có cơ sở lý thuyết vững chắc để tính toán SV cho các biến hạng mục đã được mã hóa. Việc cộng dồn SV của các biến con không chỉ sai về mặt lý thuyết mà còn có thể dẫn đến các diễn giải ngụy biện (spurious interpretations)~\citep{Aas2020}.
\end{itemize}

\subsection{Định vị Công trình Nghiên cứu}

Công trình ``Accurate Shapley Values for explaining tree-based models'' định vị mình một cách rõ ràng là một sự cải tiến và sửa chữa trực tiếp cho TreeSHAP, phương pháp giải thích hàng đầu cho các mô hình cây~\citep{Lundberg2020, Lundberg2017}. 

\begin{itemize}
    \item \textbf{Về vấn đề phụ thuộc:} Bài báo giới thiệu hai bộ ước tính mới (Discrete và Leaf-based) có nền tảng thống kê, được thiết kế để thay thế cho cơ chế ước tính bị chệch của TreeSHAP, giúp tính toán SV chính xác hơn~\citep{Aas2020}.
    \item \textbf{Về vấn đề biến hạng mục:} Đây là công trình tiên phong trong việc cung cấp một giải pháp đúng đắn về mặt lý thuyết bằng cách sử dụng khái niệm liên minh (coalition)~\citep{Aas2020}. Phương pháp này đảm bảo rằng việc mã hóa biến không làm thay đổi hay sai lệch kết quả giải thích.
\end{itemize}


\section{Kiến thức nền tảng}
\subsection{Decision Tree}
Cây quyết định là một kiểu mô hình dự báo (predictive model), nghĩa là một ánh xạ từ các quan sát về một sự vật/hiện tượng tới các kết luận về giá trị mục tiêu của sự vật/hiện tượng. Mỗi một nút trong (internal node) tương ứng với một biến; đường nối giữa nó với nút con của nó thể hiện một giá trị cụ thể cho biến đó. Mỗi nút lá đại diện cho giá trị dự đoán của biến mục tiêu, cho trước các giá trị của các biến được biểu diễn bởi đường đi từ nút gốc tới nút lá đó.

\subsection{Biến phân loại (categorical variables)}
Hay còn gọi là biến định tính (qualitative variables). Trong AI, ta có hai nhóm chính là biến định tính và biến định lượng (quantitative variables). Biến định tính có giá trị thuộc một tập hợp, ví dụ màu sắc $\in$ \{đen, nâu, đỏ, cam, vàng, lục, lam, tím, xám, trắng, hoàng kim, bạc\}, còn biến định lượng thì sẽ biễu diễn được ở dạng một số cụ thể có thể áp dụng các toán tử cơ bản được.

\subsection{Giá Trị Shapley}
Trong lí thuyết trò chơi, giá trị Shapley là một giải pháp phân phối cả lợi nhuận và chi phí một cách công bằng cho nhiều người chơi~\citep{Shapley1953}. Dù giá trị Shapley không hoàn hảo, nó đã được chứng minh là một cách tiếp cận khá công bằng.

Công thức tổng quát cho Giá trị Shapley của một liên minh đặc trưng `C` được định nghĩa trong bài báo (phương trình 2) như sau:
$$
\phi_{X_C}(f) \triangleq \frac{1}{p - |C| + 1} \sum_{k=0}^{p-|C|} \frac{1}{\binom{p-|C|}{k}} \sum_{S \in S_k(C)} [f_{S \cup C}(x_{S \cup C}) - f_S(x_S)]
$$
Trong đó:
\begin{itemize}
    \item `p` là tổng số đặc trưng.
    \item `C` là liên minh các đặc trưng đang được xem xét.
    \item `S` là một tập con các đặc trưng không bao gồm `C`.

    \item $f_S(x_S)$ là hàm dự báo rút gọn (reduced predictor) được định nghĩa là giá trị kỳ vọng của đầu ra mô hình khi chỉ biết giá trị của các đặc trưng trong tập `S`:
    
    $$
    f_S(x_S) \triangleq E[f(X) | X_S = x_S]
    $$

\end{itemize}
Việc ước tính giá trị kỳ vọng có điều kiện $E[f(X) | X_S = x_S]$ là thách thức lớn nhất trong việc tính toán Giá trị Shapley, đặc biệt khi các đặc trưng có sự phụ thuộc lẫn nhau~\citep{Aas2020}.


\section{Phương pháp nghiên cứu}

\section{Thực nghiệm và Phân tích kết quả}
\subsection{Cài đặt thực nghiệm và bộ dữ liệu}

Trong phần này, tác giả tiến hành đánh giá mức độ chính xác và đáng tin cậy của các bộ ược lượng giá trị Shapley (Shapley Values - SV) áp dụng cho mô hình cây quyết định, đặc biệt tập trung vào các trường hợp khi các đặc trưng có tương quan hoặc xuất hiện các biến rời rạc/biến phân loại. Để làm rõ sự khác biệt, tác giả chia quá trình đánh giá thành hai thí nghiệm riêng biệt.


\subsubsection{Thí nghiêm 1: Đánh giá trên mô hình tuyến tính}
    \begin{itemize}[align=parleft, left=4em, labelsep=1em, itemsep=1em]
        \item \textbf{Bộ dữ liệu:} 
          \begin{itemize}[label=$\circ$, left=1em, labelsep=0.75em, itemsep=0.5em]
            \item Bao gồm $n = 10^4$ quan sát $\{(X_i, Y_i)\}_{i=1}^{n}$, trong đó mỗi $X_i$ là vector các đặc trưng của quan sát thứ $i$ và $Y_i$ là giá trị mục tiêu tương ứng.
            
            \item $X \in \mathbb{R}^p$ với $p = 5$ đặc trưng, theo phân phối Gaussian đa biến: 
            \begin{equation*}
                X \sim \mathcal{N}(0, \Sigma), \quad 
                \Sigma = \rho J_p + (\rho - 1) I_p, \quad 
                \rho = 0.7,
            \end{equation*}
            trong đó:
            
                \begin{itemize}[label=$+$, labelsep=0.3em, itemsep=0.2em]
                    \item $J_p$ là ma trận $p \times p$ mà tất cả các phần tử đều bằng 1, và $I_p$ là ma trận đơn vị $p \times p$.

                    \item $\Sigma$ là ma trận hiệp phương sai của các đặc trưng.
            %             - Đường chéo $(\Sigma)_{ii} = 0.4$ là phương sai của từng feature.\\
            % - Ngoại biên $(\Sigma)_{ij} = 0.7$ là hiệp phương sai (covariance) giữa các feature khác nhau, tạo tương quan dương giữa các đặc trưng.
                
                \end{itemize}
            

            
            
            
            \item Biến mục tiêu:
            \begin{equation*}
                Y = B^T X,
            \end{equation*}
            với:
            
             \begin{itemize}[label=$+$, labelsep=0.3em, itemsep=0.2em]
                \item Vector $B$ chứa trọng số của từng đặc trưng, xác định mức đóng góp của mỗi đặc trưng vào $Y_i$.
             \end{itemize}
           
            
        \end{itemize}

        \item \textbf{Chỉ số đánh giá và mô hình chuẩn so sánh}
          \begin{itemize}[label=$\circ$, left=1em, labelsep=0.75em, itemsep=0.5em]
                \item Chỉ số đánh giá
                    \begin{itemize}[label=$+$, labelsep=0.3em, itemsep=0.2em]
                        \item Relative Absolute Error (RAE): đo sai khác giữa SV ước lượng và SV thực
                        \item True Positive Rate (TPR): kiểm tra thứ hạng $k$ đặc trưng quan trọng nhất
                    \end{itemize}
                \item Mô hình chuẩn so sánh
                    \begin{itemize}[label=$+$, labelsep=0.3em, itemsep=0.2em]
                        \item TreeSHAP: thuật toán chuẩn cho mô hình cây
                        \item Leaf estimator: sử dụng kỳ vọng có điều kiện trong từng lá cây
                    \end{itemize}
            \end{itemize}

            \item \textbf{Phân tích kết quả và giải thích}
            
            Kết quả trong Hình 3 cho thấy sự khác biệt rõ rệt giữa các phương pháp ước lượng Shapley Value (SV) trên tập dữ liệu trên với $p=5$ đặc trưng. Cụ thể:
              \begin{itemize}[label=$\circ$, left=1em, labelsep=0.75em, itemsep=0.5em]
                \item \textbf{TreeSHAP} ($\hat{f}_{\text{SHAP}}$) có RAE trung bình = 3.31 và TPR = 86\% (±17\%), cho thấy mức độ sai số lớn hơn và khả năng giữ nguyên thứ hạng top-k feature thấp hơn.  

                \item \textbf{Leaf estimator} ($\hat{f}_{\text{Leaf}}$) có RAE = 0.90 và TPR = 94\% (±12\%), chứng tỏ độ chính xác cao hơn TreeSHAP, đặc biệt khi các đặc trưng có tương quan.  
              \end{itemize}
            
            

            
           \textbf{Giải thích:} 

             TreeShap: Do tác giả đang giả định là khi một feature phụ thuộc vào các feature khác - tức là feature đó nằm trong xích Markov của nó - TreeSHAP vẫn giả định rằng các feature ngoài tập feature đang xét là độc lập. Giả định này đồng nghĩa với việc mọi ảnh hưởng thực sự từ các feature trong xích Markov nhưng không xuất hiện trên path của cây đều bị bỏ qua khi tính giá trị đóng góp.
                        
            Ngược lại, Leaf estimator tính giá trị kỳ vọng có điều kiện của feature trong từng leaf, dựa trực tiếp trên phân phối thực tế của feature trong lá đó. Do đó, Leaf estimator phản ánh chính xác mức đóng góp của feature ngay cả khi có sự phụ thuộc giữa các feature hoặc dữ liệu không liên tục. Kết quả là Leaf estimator ít bị bias hơn và cho các giá trị Shapley gần với true SV hơn, giúp giải thích mô hình đáng tin cậy hơn.


        
    \end{itemize}




\section{Kết luận và định hướng nghiên cứu tương lai}

\subsection{Kết luận}

Chúng tôi đã chỉ ra rằng việc triển khai hiện tại của Shapley Values (SV) có thể dẫn đến các giải thích thiếu tin cậy do ước lượng bị sai lệch hoặc xử lý không phù hợp với biến phân loại. Để khắc phục vấn đề này, chúng tôi đã đề xuất các bộ ước lượng mới và đưa ra phương pháp đúng để xử lý biến phân loại. 

Kết quả thực nghiệm cho thấy ngay cả trong những mô hình đơn giản, sự khác biệt giữa phương pháp tiên tiến hiện nay (TreeSHAP) và các phương pháp được đề xuất là đáng kể.

Mặc dù có sự quan tâm ngày càng lớn đến lĩnh vực AI đáng tin cậy, tác động của những sai lệch này trong giải thích vẫn chưa được hiểu rõ. Nguyên nhân là do khó khăn trong việc đánh giá định lượng chất lượng của một lời giải thích, vốn phụ thuộc vào phân phối dữ liệu gốc, thứ rất khó để ước lượng. Hơn nữa, quá trình đánh giá thường dễ bị ảnh hưởng bởi thiên kiến xác nhận (confirmation bias).

Chúng tôi cũng cho rằng chất lượng ước lượng không phải là hạn chế duy nhất của SV. Thực tế, chúng tôi chứng minh trong Mệnh đề 5.1 rằng giải thích bằng SV không phải là giải thích cục bộ (local), mà vẫn mang tính toàn cục (global), ngay cả trong mô hình tuyến tính đơn giản.

Mệnh đề 5.1 cho thấy rằng SV không thực sự đo lường mang tính cục bộ, mà thay vào đó vẫn chịu ảnh hưởng toàn cục. Nguyên nhân là khi tính SV cho $X_1$ hoặc $X_2$, ta cũng xem xét các tập con $S$ không chứa $X_5$. Quá trình lấy trung bình và thay đổi dấu của $X_5$ đã vô tình đưa cả mô hình tuyến tính còn lại (không áp dụng cho quan sát hiện tại) vào. 

Phát hiện này đặt ra những thách thức lớn trong việc diễn giải SV và cho thấy các hạn chế thường bị bỏ qua trong thực tiễn do thiếu sự chính xác và hiểu biết về Shapley Values.

\subsection{Định hướng nghiên cứu tương lai}

Trong tương lai, có thể tập trung vào các hướng sau:
\begin{itemize}
    \item Phát triển bộ chuẩn đánh giá hệ thống cho chất lượng giải thích trong AI. 
    \item Nghiên cứu các phương pháp thay thế SV mang lại giải thích thực sự cục bộ. 
    \item Mở rộng phân tích sang mô hình phi tuyến và không gian chiều cao. 
    \item Khảo sát tác động tâm lý và thực tiễn của các sai lệch trong giải thích AI khi áp dụng trong các hệ thống thực tế. 
\end{itemize}

\end{document}
\bibliographystyle{plainnat}
\bibliography{references}  

\end{document}
